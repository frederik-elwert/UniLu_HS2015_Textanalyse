{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendung 1: Keyword Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine mögliche Anwendung von Textanalysen auf der Grundlage eines Vector-Space-Modells ist die Identifikation von Schlüsselwörtern für Texte, die »Keyword Extraction«. Ein Schlüsselwort kann verstanden werden als ein Wort, dass einen inhaltlichen Aspekt eines Textes beschreibt. Eine begrenzte Anzahl von Schlüsselwörtern sollte also bereits einen guten Eindruck vom Inhalt eines Textes vermitteln. Schlagwortsysteme, etwa in Bibliothekskatalogen oder Literaturdatenbanken, bauen auf dieser Idee auf. Sie erfordern aber eine sorgfältige manuelle Verschlagwortung. Daher ist die Frage interessant, ob sich Schlüsselwörter für Texte auch automatisch aus dem Textinhalt erschließen lassen.\n",
    "\n",
    "Ein erster Kandidat für die Identifikation wäre die reine Worthäufigkeit: Für einen Text relevante Wörter sollten in ihm häufig vorkommen. Die Häufigkeitsauszählungen aus den vorangegangenen Einheiten zeigen aber, dass eine reine Häufigkeitsliste nicht sehr hilfreich ist: Zunächst erscheinen Funktionwörter wie etwa Artikel ganz oben in der Liste. Aber auch wenn man nach Wortarten filtert, bleiben oft relativ unspezifische Wörter dominant.\n",
    "\n",
    "Der Keyword Extraction liegt daher die Annahme zugrunde, dass einige Wörter insgesamt häufig vorkommen, ohne dass sie inhaltlich aussagekräftig wären. Ihr häufiges Vorkommen ist daher eher charakteristisch für eine (Fach-)Sprache als für einzelne Texte. Die Verteilung dieser Wörter sollte entsprechend über die Texte relativ gleich bleiben. Ein Schlüsselwort dagegen sollte im entsprechenden Text deutlich häufiger vorkommen als im Gesamtkorpus. Statistisch lässt sich ein Schlüsselwort also definieren als ein Wort, das in einem einzelnen Text signifikant häufiger vorkommt als seine Häufigkeit im Gesamtcorpus erwarten lassen würde.\n",
    "\n",
    "Eine Form einer entsprechenden Identifikation von Schlüsselwörtern ist [Tf-Idf](http://de.wikipedia.org/wiki/Tf-idf-Ma%C3%9F). Das Kürzel steht dabei für »Termfrequenz – Inverse Dokumentfrequenz«.\n",
    "\n",
    "Dieses Verfahren ist in gensim implementiert. Dafür wird die in der vorangegangenen Einheit vorgestellte Corpus-Klasse verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.corpora.textcorpus import TextCorpus\n",
    "from textblob_de import TextBlobDE as TextBlob\n",
    "import pandas as pd\n",
    "\n",
    "class CSVCorpus(TextCorpus):\n",
    "    \"\"\"Read corpus from a csv file.\"\"\"\n",
    "\n",
    "    def get_texts(self):\n",
    "        with self.getstream() as csvfile:  # Öffnet die CSV-Datei\n",
    "            table = pd.read_csv(csvfile, parse_dates=['date'], encoding='utf-8')  # Liest die CSV-Datei\n",
    "            for text in table['text']:  # Verarbeite die einzelnen Texte aus der Spalte 'text'\n",
    "                blob = TextBlob(text)\n",
    "                yield blob.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Vorgehen in gensim ist dabei nicht ganz selbsterklären, daher hier eine kurze Erläuterung: Der Befehl `TfidfModel(corpus)` erzeugt zunächst ein Modell, das die allgemeine Häufigkeitsverteilung von Wörtern im Corpus enthält. Mit diesem Modell können nun einzelne Dokumente, aber auch nur einzelne Wörter aus einem Dokument, verglichen werden. Dies ist etwa dann sinnvoll, wenn eine Berechnung für das gesamte Corpus zu aufwändig wäre, oder wenn neue Texte hinzukommen, die mit einem bestehenden Corpus verglichen werden sollen.\n",
    "\n",
    "Um dagegen für das gesamte Corpus die Tf-Idf-Werte zu berechnen, wird dem Modell im zweiten Schritt einfach wiederum das gesamte Corpus übergeben: `tf_idf[corpus]`. In diesem Schritt findet dann die eigentliche Berechnung für die einzelnen Dokument statt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel\n",
    "\n",
    "corpus = CSVCorpus(\"../Daten/reden.csv\")\n",
    "tf_idf = TfidfModel(corpus)\n",
    "corpus_idf = tf_idf[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies gibt für jedes Wort in jedem Dokument einen Wert aus. Das Format ist dabei das gleiche wie für Corpora, nur dass anstelle der reinen Worthäufigkeiten der tfidf-Wert ausgegeben wird. Ein Dokument ist also eine Liste aus `(wortindex, wert)`-Paaren.\n",
    "\n",
    "Um nun für einzelne Dokumente die Schlüsselwörter zu bestimmen, ist es sinnvoll, die Wörter im Dokument nach ihrem tfidf-Wert zu sortieren. Zugleich interessieren nicht die numerischen Wort-Indices, sondern die eigentlichen Wörter. Daher wird hier eine Funktion `keywords` definiert, die das Dokument zunächst nach tfidf-Wert (dem zweiten Eintrag im Wort-Wert-Paar: `x[1]`) sortiert und dann ein Paar aus Wörterbucheintrag `corpus.dictionary[term]` und tfidf-Wert ausgibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def keywords(corpus, doc_tf_idf):\n",
    "    return [(corpus.dictionary[term], value)\n",
    "            for term, value\n",
    "            in sorted(doc_tf_idf, key=lambda x: x[1], reverse=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die ersten zehn Dokumente können nun etwa jeweils fünf Schlüsselwörter ausgegeben werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Safranski (0.472750464052)\n",
      "  Rüdiger (0.337367236021)\n",
      "  Wahrheiten (0.138215543768)\n",
      "  Utopien (0.126066790414)\n",
      "  Romantik (0.104493794377)\n",
      "\n",
      "  „Elektromobilität“ (0.372779168826)\n",
      "  Stecker (0.372435485485)\n",
      "  Elektromobilität (0.173383544659)\n",
      "  Präsentation (0.171540045793)\n",
      "  China (0.162105143183)\n",
      "\n",
      "  Nachhaltigkeit (0.294015094791)\n",
      "  China (0.291787735475)\n",
      "  Universität (0.109320088669)\n",
      "  Innovationspartnerschaft (0.1065077783)\n",
      "  Chinas (0.102461803818)\n",
      "\n",
      "  Tempelhof (0.556694789109)\n",
      "  Flughafen (0.292116704843)\n",
      "  AlliiertenMuseum (0.209741456143)\n",
      "  Berlin-Tempelhof (0.151825851575)\n",
      "  Miniaturbild (0.151825851575)\n",
      "\n",
      "  „Sonne“ (0.446115651832)\n",
      "  Schiff (0.272536385343)\n",
      "  Neptun (0.227323234857)\n",
      "  Werft (0.213883738352)\n",
      "  Meeresforschung (0.188422877129)\n",
      "\n",
      "  Klimaschutz (0.192756524708)\n",
      "  Hendricks (0.152513059156)\n",
      "  Umweltminister (0.14994348321)\n",
      "  Energien (0.13244948829)\n",
      "  2030 (0.125330990937)\n",
      "\n",
      "  Bevölkerungsschutz (0.211489490766)\n",
      "  Bevölkerungsschutzes (0.211489490766)\n",
      "  Haupt (0.185891928075)\n",
      "  Verzicht (0.165225609843)\n",
      "  freiwilligen (0.148534035723)\n",
      "\n",
      "  Wirtschaftswissenschaften (0.164377237199)\n",
      "  Wissenschaft (0.158895097718)\n",
      "  Lindau (0.138204437541)\n",
      "  Theorien (0.13284385955)\n",
      "  Politikberatung (0.108361418257)\n",
      "\n",
      "  Vertriebenen (0.648749225458)\n",
      "  Vertreibung (0.296323531462)\n",
      "  Flucht (0.258747401451)\n",
      "  Heimat (0.115601389578)\n",
      "  Schicksal (0.114708666597)\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(corpus_idf):\n",
    "    if i == 9:\n",
    "        break\n",
    "    print\n",
    "    for keyword, value in keywords(corpus, doc)[0:5]:\n",
    "        print u'  {} ({})'.format(keyword, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier ist auffällig, dass fast nur Substantive ausgegeben werden, obwohl das Corpus selbst die Wörter überhaupt nicht gefiltert hat. Dies legt den Schluss nahe, dass andere Wortarten deutlich gleicher über das Corpus verteilt sind.\n",
    "\n",
    "Um die Plausibilität dieser Listen zu überprüfen, können zusätzlich die Titel der Dokumente ausgegeben werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Laudatio auf Rüdiger Safranski\n",
      "  Safranski (0.472750464052)\n",
      "  Rüdiger (0.337367236021)\n",
      "  Wahrheiten (0.138215543768)\n",
      "  Utopien (0.126066790414)\n",
      "  Romantik (0.104493794377)\n",
      "\n",
      "Rede von Bundeskanzlerin Merkel anlässlich der Präsentation des deutsch-chinesischen Kooperationsprojekts zur Ladeinfrastruktur für Elektrofahrzeuge am 8. Juli 2014\n",
      "  „Elektromobilität“ (0.372779168826)\n",
      "  Stecker (0.372435485485)\n",
      "  Elektromobilität (0.173383544659)\n",
      "  Präsentation (0.171540045793)\n",
      "  China (0.162105143183)\n",
      "\n",
      "Rede von Bundeskanzlerin Merkel anlässlich des Besuchs der Tsinghua - Universität am 8. Juli 2014\n",
      "  Nachhaltigkeit (0.294015094791)\n",
      "  China (0.291787735475)\n",
      "  Universität (0.109320088669)\n",
      "  Innovationspartnerschaft (0.1065077783)\n",
      "  Chinas (0.102461803818)\n",
      "\n",
      "Kulturstaatsministerin Monika Grütters zur Eröffnung der Sonderausstellung\n",
      "\"Flughafen Berlin-Tempelhof - Die amerikanische Geschichte\"\n",
      "  Tempelhof (0.556694789109)\n",
      "  Flughafen (0.292116704843)\n",
      "  AlliiertenMuseum (0.209741456143)\n",
      "  Berlin-Tempelhof (0.151825851575)\n",
      "  Miniaturbild (0.151825851575)\n",
      "\n",
      "Rede von Bundeskanzlerin Merkel anlässlich der Taufe des Tiefseeforschungsschiffs „Sonne“ am 11. Juli 2014 \n",
      "  „Sonne“ (0.446115651832)\n",
      "  Schiff (0.272536385343)\n",
      "  Neptun (0.227323234857)\n",
      "  Werft (0.213883738352)\n",
      "  Meeresforschung (0.188422877129)\n",
      "\n",
      "Rede von Bundeskanzlerin Merkel anlässlich des 5. Petersberger Klimadialogs am 14. Juli 2014\n",
      "  Klimaschutz (0.192756524708)\n",
      "  Hendricks (0.152513059156)\n",
      "  Umweltminister (0.14994348321)\n",
      "  Energien (0.13244948829)\n",
      "  2030 (0.125330990937)\n",
      "\n",
      "Rede von Bundeskanzlerin Merkel zum Treffen mit BBK, THW und den Hilfsorganisationen im Bereich des Bevölkerungsschutzes am 19. August 2014 in Bonn\n",
      "  Bevölkerungsschutz (0.211489490766)\n",
      "  Bevölkerungsschutzes (0.211489490766)\n",
      "  Haupt (0.185891928075)\n",
      "  Verzicht (0.165225609843)\n",
      "  freiwilligen (0.148534035723)\n",
      "\n",
      "Rede von Bundeskanzlerin Merkel zum 5. Treffen der Nobelpreisträger\n",
      "  Wirtschaftswissenschaften (0.164377237199)\n",
      "  Wissenschaft (0.158895097718)\n",
      "  Lindau (0.138204437541)\n",
      "  Theorien (0.13284385955)\n",
      "  Politikberatung (0.108361418257)\n",
      "\n",
      "Rede von Bundeskanzlerin Merkel zum Tag der Heimat am 30. August 2014\n",
      "  Vertriebenen (0.648749225458)\n",
      "  Vertreibung (0.296323531462)\n",
      "  Flucht (0.258747401451)\n",
      "  Heimat (0.115601389578)\n",
      "  Schicksal (0.114708666597)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../Daten/reden.csv\", parse_dates=['date'], encoding='utf-8')\n",
    "\n",
    "for i, doc in enumerate(corpus_idf):\n",
    "    if i == 9:\n",
    "        break\n",
    "    print\n",
    "    print data['title'][i]\n",
    "    for keyword, value in keywords(corpus, doc)[0:5]:\n",
    "        print u'  {} ({})'.format(keyword, value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
